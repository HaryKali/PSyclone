# LFRic: A quick introduction

**LFRic** is the new weather and climate modelling system being developed
by the UK Met Office (UKMO) to replace the existing Unified Model (UM)
in preparation for exascale computing in the 2020s. LFRic uses the GungHo
dynamical core and runs on a semi-structured cubed-sphere mesh.

The design of the supporting infrastructure follows object-oriented
principles to facilitate modularity and the use of external libraries.
One of the guiding design principles, imposed to promote performance
portability, is **separation of concerns** between the science code and
parallel code.

**PSyclone** generates the parallel code for shared and distributed
memory support on CPUs via the LFRic (Dynamo 0.3) API. The generated
code calls the appropriate functionality from the LFRic infrastructure
(e.g. halo exchange, colouring). PSyclone optimisations are routinely
used in building and running LFRic. Together with the developing
support for accelerators, PSyclone aims to facilitate deployment of a
single-source science code onto different machine architectures.

## LFRic repository and wiki

The LFRic repository and the associated wiki are hosted at the Met Office
Science Repository Service [(MOSRS)](https://code.metoffice.gov.uk/trac/home).
The code is BSD-licensed, however browsing the
[LFRic wiki](https://code.metoffice.gov.uk/trac/lfric/wiki) and
[code repository](https://code.metoffice.gov.uk/trac/lfric/browser) requires
login access to MOSRS. Please contact the LFRic team manager,
[Steve Mullerworth](mailto:steve.mullerworth@metoffice.gov.uk), to be granted
access to the repository.

Another useful contact for LFRic-related questions is the
["lfric" mailing list](mailto:lfric@cmpd1.metoffice.gov.uk) which gathers
the Met Office and external LFRic developers and users.

### PSyclone in LFRic

PSyclone LFRic (Dynamo 0.3) API documentation can be found [here.](
https://psyclone.readthedocs.io/en/stable/dynamo0p3.html#valid-access-modes)

LFRic wiki hosts pages on the use of PSyclone in LFRic, starting with the
[PSyclone in LFRic wiki](https://code.metoffice.gov.uk/trac/lfric/wiki/PSycloneTool).

Not every PSyclone release works with every LFRic trunk revision. The LFRic - PSyclone
compatibility table is give in this [LFRic wiki (requires login)](
https://code.metoffice.gov.uk/trac/lfric/wiki/LFRicTechnical/VersionsCompatibility).

## LFRic code structure

The LFRic code is rapidly developing. A recent snapshot of LFRic trunk
[(revision 25636, Oct 2020)](
https://code.metoffice.gov.uk/trac/lfric/browser/LFRic/trunk?rev=25636)
is structured as follows:

* `bin` - [Rose-based](
   https://www.metoffice.gov.uk/research/approach/modelling-systems/rose) executables;

* `extra` - Utilities (e.g. job submission scripts);

* `gungho` - GungHo dynamical core (one of the main science applications);

* `infrastructure` - LFRic infrastructure supporting science applications;

* `jules` - Interface to the UKMO [JULES land surface model](
   https://www.metoffice.gov.uk/research/approach/collaboration/jwcrp/jules);

* `lfric_atm` - LFRic atmospheric model that uses GungHo dynamical core and
                interfaces to UM Physics, JULES and SOCRATES;

* `mesh_tools` - Mesh generation tools;

* `miniapps` - "Standalone" science and infrastructure applications (e.g.
                Gravity Wave application);

* `socrates` - Interface to the UKMO radiative transfer ("Suite Of Community
               RAdiative Transfer codes") model;

* `um_physics` - Interface to the UKMO UM Physics parameterisation schemes.

### Languages and software requirements

The main languages used in LFRic are
[Fortran 2003](https://gcc.gnu.org/wiki/GFortranStandards#Fortran_2003)
and [Python 3.](https://www.python.org/download/releases/3.0/)

Checking out the LFRic trunk can be done using [Subversion](
https://subversion.apache.org/) or [FCM](https://metomi.github.io/fcm/doc/)
version control systems. `SVN` is recommended for checking out the code for
runs only as it is easier to install. `FCM` is used for LFRic development.

Some of software requirements are described in the main
[README](../README.md) document for this tutorial. A recipe for building
the full LFRic software stack with freely available GCC Fortran compiler
10.2.0 and othere requirements can be found in this
[Met Office GitHub repository.](
https://github.com/MetOffice/NGMS-SoftwareStack/tree/main/buildScripts/Linux/GCC10)

## Separation of concerns

Applications in LFRic directories build on the principle of *separation
of concerns* between the science code and parallel code. The source in
each is divided into the following layers:

* **Driver** - Set up and control of a model run (e.g. domain, partition,
  science configuration, checkpoint);
* [**Algorithm**](LFRic_algorithm.md) - Science code performing high-level
  mathematical operations (e.g. time-stepping) on LFRic objects;
* [**PSy**](LFRic_PSy.md) - Parallel code either generated by PSyclone (not
  included in the LFRic repository) or hand-written to prototype and
  test the functionality not yet available in PSyclone (included in the
  repository as `psykal_lite_*_mod.(F)f90` files);
* [**Kernel**](LFRic_kernel.md) - Science code performing low-level
  mathematical operations (e.g. matrix assembly, calculating gradient)
  on the data contained in LFRic objects.

This above illustrated separation of concerns is called **PSyKAl**, from
*Parallel Systems* (computational science applying optimisations),
*Kernels*(natural science performing operations on data points) and
*Algorithms* (natural science performing operations on whole fields).

All of this is supported by the **LFRic infrastructure**, a collection
of **objects** that encapsulate data and functionality representing the
main model structures such as mesh, partition, finite-element function
spaces, fields, operators, etc. The schematic of the overall PSyKAl
structure is shown in the figure below (courtesy of the UKMO LFRic team).

![PSyKAl Separation of concerns in LFRic](separation_concerns.png)

## References

* Adams SV, Ford RW, Hambley M, Hobson JM, Kavcic I, Maynard CM, Melvin T,
  Mueller EH, Mullerworth S, Porter AR, Rezny M, Shipway BJ and Wong R (2019):
  [LFRic: Meeting the challenges of scalability and performance portability
  in Weather and Climate models.](
  https://doi.org/10.1016/j.jpdc.2019.02.007) Journal of Parallel and
  Distributed Computing.
* [Met Office research news, May 2019](
  https://www.metoffice.gov.uk/research/news/2019/gungho-and-lfric)